{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "2) Find the similarity between two sentences or paragraphs.This assignment will help you to become familiar with NLP functionalities such as tokenization, stemming, and word embeddings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shelton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shelton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140836\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "if not os.path.exists('file.txt'):\n",
    "    url = 'https://www.gutenberg.org/files/98/98-0.txt'\n",
    "    response = requests.get(url)\n",
    "    with open('file.txt', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "# model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text_returned = re.sub(\"’s\",'',text)\n",
    "    regex = re.compile('[^a-zA-Z0-9\\’s]')\n",
    "    text_returned = re.sub(regex, ' ', text_returned)\n",
    "    return text_returned\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "text = read_file('file.txt')\n",
    "processed_text = nlp(text)\n",
    "processed_text = remove_special_characters(processed_text.text)\n",
    "\n",
    "stemmed_words = [[stemmer.stem(word)] for word in processed_text.split()]\n",
    "\n",
    "print(len(stemmed_words))\n",
    "\n",
    "model = Word2Vec(sentences=stemmed_words, vector_size=300, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec1.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i']\n",
      "['like']\n",
      "['eat']\n",
      "['appl']\n",
      "['i']\n",
      "['don’t', 'don’t', 'don’t']\n",
      "['like']\n",
      "['eat']\n",
      "['appl']\n",
      "0.62059\n",
      "The similarity between sentence 1 and sentence 2: 0.620586633682251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shelton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i']\n",
      "['like']\n",
      "['eat']\n",
      "['appl']\n",
      "['the']\n",
      "['tabl']\n",
      "['is']\n",
      "['made']\n",
      "['of']\n",
      "['wood']\n",
      "0.0718\n",
      "The similarity between sentence 1 and sentence 2: 0.07180331647396088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shelton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i']\n",
      "['like']\n",
      "['eat']\n",
      "['appl']\n",
      "['the']\n",
      "['tabl']\n",
      "['is']\n",
      "['made']\n",
      "['of']\n",
      "['wood']\n",
      "0.0718\n",
      "The similarity between sentence 1 and sentence 2: 0.07180331647396088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shelton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# Function to average word vectors for a text\n",
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def average_word_vectors(words, model, num_features):\n",
    "    feature_vec = np.zeros((num_features,), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if \"'\" in word:\n",
    "            word = word.replace(\"'\", \"’\")\n",
    "        stemmed_words = [stemmer.stem(word) for words in word_tokenize(word)]\n",
    "        print(stemmed_words)\n",
    "        for stemmed_word in stemmed_words:\n",
    "            if stemmed_word in model.wv:\n",
    "                n_words += 1\n",
    "                feature_vec = np.add(feature_vec, model.wv[stemmed_word])\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "# Calculate average feature vectors for sentences\n",
    "sentence1 = \"I liked eating apples\"\n",
    "sentence2 = \"The table is made of wood\"\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokenize(sentence1)]\n",
    "\n",
    "sentence1_avg_vector = average_word_vectors(sentence1.split(), model=model, num_features=300)\n",
    "sentence2_avg_vector = average_word_vectors(sentence2.split(), model=model, num_features=300)\n",
    "# print(sentence1_avg_vector)\n",
    "# print(sentence2_avg_vector)\n",
    "# Reshape to 1-d arrays\n",
    "sentence1_avg_vector = sentence1_avg_vector.reshape(1, -1)\n",
    "sentence2_avg_vector = sentence2_avg_vector.reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(sentence1_avg_vector, sentence2_avg_vector)\n",
    "print(round(cosine_sim[0][0],5))\n",
    "print(f\"The similarity between sentence 1 and sentence 2: {cosine_sim[0][0]}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# print(model.wv.key_to_index)\n",
    "# print(model.wv[\"don’t\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# target_word = 'a'\n",
    "#\n",
    "# all_words = [word for word, _ in model.wv.key_to_index.items()]\n",
    "# similarities = [(word, model.wv.similarity(target_word, word)) for word in all_words if word != target_word]\n",
    "#\n",
    "# # Sort by similarity\n",
    "# sorted_similarities = sorted(similarities, key=lambda x: x[1])\n",
    "#\n",
    "# # Get the least similar words\n",
    "# least_similar_words = sorted_similarities[:5]\n",
    "#\n",
    "# # Print the results\n",
    "# for word, similarity in least_similar_words:\n",
    "#     print(f\"{word}: {similarity}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
